#!/usr/bin/env python

'''Generate the AROS WWW site.

The process works like this:

- First, the contents of all manually created pages is converted to
partial HTML. Manually created pages are pages where the content comes
from some kind of source file. Partial HTML is HTML which goes into
the "meat" part of the page and which can contain placeholders, namely
VHREFs or virtual HRefs like this:

    <a vhref="Documentation">

These will be replaced by normal hrefs which point to the document
which is known as "Documentation".
'''

import glob
from util import *

def genDocumentation ():
    page = PageMeat ('Documentation', 'documentation.html')
    page.append (
	Heading (2, 'Documentation'),
	Paragraph ('Please choose a link to the left'),
    )
    page.write ()
    #n = mainLinks2.getNode (page)
    #print "n=",n
    #print "n.parent=",n.parent
    #print "n.parent.parent=",n.parent.parent
    return page


pm = PageMeat ('Index', 'index.html')
pm.append (Text ('You are now being redirected to'),\
           Href('http://aros.sourceforge.net/', 'http://aros.sourceforge.net/'), \
           Text('. If it does not work, please click'), \
           Href('http://aros.sourceforge.net/', 'here'), Text('.'))

pm.write ()

#print 'root=',mainLinks2.root
#pm = PageMeat ('Test2', 'test1.html')
#pm.append (Text ('Test2'))
#pm.write ()
#pm = PageMeat ('Test2/Test', 'test1.html')
#pm.append (Text ('Test2'))
#pm.write ()
#print 'root.order=',mainLinks2.root.order
#node = mainLinks2.getNode (pm)
#print 'node=',node
#print 'node.parent=',node.parent
#print 'node.parent.parent=',node.parent.parent

def genScreenshots ():
    '''Create a page with screenshots.'''

    page = PageMeat ('Screenshots', 'screenshots.html')

    # First, the pictures of AROS developers, etc.
    tn1  = Thumbnail ('pics/developers/Digulla-2.jpg')
    tn2  = Thumbnail ('pics/developers/Digulla-1.jpg')
    tn3  = Thumbnail ('pics/developers/nlorentz.jpg')
    tn4  = Thumbnail ('pics/developers/periksson.jpg')
    tn5  = Thumbnail ('pics/developers/sheutling.jpg')
    tn6  = Thumbnail ('pics/developers/falemagn.jpg')
    tn7  = Thumbnail ('pics/developers/hkiel.jpg')
    tn8  = Thumbnail ('pics/developers/mparsons.jpg')
    tn9  = Thumbnail ('pics/developers/michael_schulz.jpg')
    tn10 = Thumbnail ('pics/developers/falemagn2.jpg')
    tn11 = Thumbnail ('pics/developers/chodorowski-1.jpeg')
    tn12 = Thumbnail ('pics/developers/chodorowski-2.jpeg' )
    tn13 = Thumbnail ('pics/developers/OlaJensen.jpg')
    tn14 = Thumbnail ('pics/developers/AlemagnaDigulla.jpg')
    tn15 = Thumbnail ('pics/developers/dlecorfec.jpg')
    page.append (
	Href ('#PicturesAroundAROS', '1. Pictures around AROS'),
	BR (),
	Href ('#Screenshots', '2. Screenshots'),
	BR (),
	BR(), HR(), BR(),
	Name ('PicturesAroundAROS'),
	Heading (2, '1. Pictures around AROS'),
	Paragraph ('If you ever wanted to know what Aaron "Optimizer" Digulla'
	    ' looks like, here are some pictures:'),
	ThumbnailTable (tn1, tn2, tn14),
	Paragraph ('Picture of Nils Henrik Lorentzen:'),
	ThumbnailTable (tn3),
	Paragraph ('Picture of Peter Eriksson:'),
	ThumbnailTable (tn4),
	Paragraph ('Picture of Sebastian Heutling:'),
	ThumbnailTable (tn5),
	Paragraph ('Pictures of Fabio Alemagna:'),
	ThumbnailTable (tn6, tn10),
	Paragraph ('Picture of Henning Kiel:'),
	ThumbnailTable (tn7),
	Paragraph ('Picture of Matt Parsons:'),
	ThumbnailTable (tn8),
	Paragraph ('Picture of Michael Schulz:'),
	ThumbnailTable (tn9),
	Paragraph ('Pictures of Adam Chodorowski:'),
	ThumbnailTable (tn11, tn12),
	Paragraph ('Picture of Ola Jensen:'),
	ThumbnailTable (tn13),
	Paragraph ('Picture of David Le Corfec:'),
	ThumbnailTable (tn15),
	Paragraph ('Hopefully, more pictures of AROS developers will'
	    ' show up here :-)'),
	Name ('Screenshots'),
	Heading (2, '2. Screenshots'),
    )

    page.linksToFix.append (tn1.href)
    page.imagesToFix.append (tn1.img)
    page.linksToFix.append (tn2.href)
    page.imagesToFix.append (tn2.img)
    page.linksToFix.append (tn3.href)
    page.imagesToFix.append (tn3.img)
    page.linksToFix.append (tn4.href)
    page.imagesToFix.append (tn4.img)
    page.linksToFix.append (tn5.href)
    page.imagesToFix.append (tn5.img)
    page.linksToFix.append (tn6.href)
    page.imagesToFix.append (tn6.img)

    def processDir (dir, page=page):
	'''Read a directory and put all pictures in it into ThumbnailTables.
	The name of the directory must be YYYYMMDD.'''
	str = os.path.basename (dir)
	date = '%d.%d.%d' % (
	    int (str[6:8]),
	    int (str[4:6]),
	    int (str[0:4]),
	)
	fh = open (os.path.join (dir, 'README'), 'r')
	text = fh.read ()
	fh.close ()

	list = [
	    Paragraph (RawText ('%s - %s' % (date, text))),
	]
	files = glob.glob (os.path.join (dir, "*.*"))
	files.sort ()
	pics = []
	for file in files:
	    if file[-4:] == '.txt' or string.find (file, '_mini.') != -1:
		continue

	    tn = Thumbnail (
		os.path.join (
		    screenshoturl,
		    str,
		    os.path.basename (file)
		)
	    )
	    pics.append (tn)
	    page.linksToFix.append (tn.href)
	    page.imagesToFix.append (tn.img)

	list.append (apply (ThumbnailTable, pics))
	return list

    # Read all screenshots and sort them by date.
    dirs = glob.glob (os.path.join (screenshoturl, '[0-9]*'))
    dirs.sort ()
    dirs.reverse ()
    for dir in dirs:
	page.extend (processDir (dir))

    page.write ()

import links

def genDownload ():
    page = PageMeat ('Downloads', 'download.html')
    # Create the page for downloads
    page.extend ([
	Heading (2, 'Downloads'),
	Paragraph ('Some places where you can find files related to AROS:'),
    ])
    page.append (processLinks (links.downloadLinks))
    page.write ()

import time

def genSnapshots ():
    '''From now on, the snapshots are only available on the SF site.'''

    page = PageMeat ('Snapshots', 'snapshots.html')
    page.append (
	Heading (2, "Snapshots"),
	Paragraph ("""From now on, you can find the list of snapshots """,
	    Href ("http://aros.sourceforge.net/snapshots.html",
		"on the SourceForge.net pages"),
	    "."),
	Paragraph ("""Go there to download and then return here with the
		back button of your browser."""),
    )
    page.write ()

def processLinks (links):
    list = List ()

    for link in links:
	if type (link) == type (()):
	    link, children = link[0], link[1:]
	else:
	    children = None

	text = Text (link.href)
	if link.text:
	    if type (link.text) == type (()):
		t = Text ()
		for item in link.text:
		    t.append (item)
	    else:
		t = Text (link.text)
	    text.append (t)
	if link.logo:
	    text.append (Image ((link.logo)))

	list.append (text)

	if children:
	    sublist = processLinks (children)
	    list.append (sublist)

    return list

def genLinks ():
    '''Create a page with links from links.py.'''
    def processSection (links, title):
	body = []

	#print title, list

	body.append (Name (title))
	body.append (Heading (2, title))
	try:
	    list = processLinks (links)
	except:
	    print 'processSection',title
	    raise
	body.append (list)

	return body

    page = PageMeat ('Links', 'links.html')
    page.append (
	Href ('#Mirrors', 'Mirrors'),
	BR(),
	Href ('#More Related', 'More Related'),
	BR(),
	Href ('#Articles', 'Articles'),
	BR(),
	Href ('#Homepages', 'Homepages'),
	BR(),
	Href ('#Less Related', 'Less Related'),
	BR(),
	BR(), HR(), BR(),
    )

    page.extend (processSection (links.mirrors, 'Mirrors'))
    page.extend (processSection (links.moreRelated, 'More Related'))
    page.extend (processSection (links.articles, 'Articles'))
    page.extend (processSection (links.homepages, 'Homepages'))
    page.extend (processSection (links.lessRelated, 'Less Related'))

    page.write ()

import xml2html, xmlsupport

class XmlPageMeat (PageMeat):
    def __init__ (self, key, url, xmlfilename):
	PageMeat.__init__ (self, key, url)

	xmlfile = xmlsupport.AROSXmlFile ()

	XML2HTML = xml2html.Xml2HtmlProcessor ()
	XML2HTML.toccount = [0, 0, 0, 0, 0]
	XML2HTML.toc = []

	xmlfile.parse (xmlfilename)
	xmlfile.process (XML2HTML)
	if XML2HTML.toc:
	    self.extend (XML2HTML.toc)
	    self.extend ([BR(), HR (), BR()])
	self.append (RawText (XML2HTML.fh.getvalue ()))
	XML2HTML.fh.close ()

docsrcdir = os.path.join (arosdir, 'docs', 'src')
def DocSrcDir (path):
    return os.path.join (docsrcdir, path)

def genPartialXmlPage (key, basename):
    xmlfilename = DocSrcDir(basename+'.xml')
    pp = XmlPageMeat (key, basename+'.html', xmlfilename)
    pp.write ()

def genPartialFAQ ():
    import faq

    faqobj = faq.FAQ (os.path.join (arosdir, 'docs', 'faq'),)
    xml = faqobj.toXml ()

    pm = PageMeat ('Documentation/FAQ', 'faq.html')
    pm.extend (xml2html.elementToHtml (xml))
    pm.write ()

# Call all generators in turn

import news
news.gen (datadir)

import status
status.gen (PageMeat)

genDocumentation ()
genPartialXmlPage ('Documentation/Background', 'background')
genPartialFAQ ()
genPartialXmlPage ('Documentation/CVS', 'cvs')
genPartialXmlPage ('Documentation/MetaMake', 'mmake')
genPartialXmlPage ('Documentation/Coding Style', 'style')
genPartialXmlPage ('Documentation/AROS XML', 'xml')
genPartialXmlPage ('Documentation/Filesystems', 'filesys')
genPartialXmlPage ('Documentation/HIDD Intro', 'hidd-intro')
genPartialXmlPage ('Documentation/HIDD Model', 'hidd-model')

import contents2html
contents2html.gen (PageMeat)

import htmlautodocs
htmlautodocs.gen ()

genPartialXmlPage ('Documentation/Random Ideas', 'ideas')

node = mainLinks2.findNode ('Documentation/AutoDocs')
node.order.sort ()
#print node,node.order

genScreenshots ()
genDownload ()
genSnapshots ()
genLinks ()

processPartialPages ()

